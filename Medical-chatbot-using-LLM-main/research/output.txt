print("Hello world")

--------------------------------------------------------------------------------
import os
os.chdir("../")

--------------------------------------------------------------------------------
%pwd

--------------------------------------------------------------------------------
from langchain import PromptTemplate
from langchain.chains import RetrievalQA
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import Pinecone
import pinecone
from langchain.document_loaders import PyPDFLoader , DirectoryLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.prompts import PromptTemplate
from langchain.llms import CTransformers

--------------------------------------------------------------------------------
## Extract the data from the PDF

--------------------------------------------------------------------------------
def load_pdf(data):
    
    loader = DirectoryLoader(data, glob="*.pdf", loader_cls=PyPDFLoader)
    documents = loader.load()
    return documents

--------------------------------------------------------------------------------
extraccted_data=load_pdf(data ="Data/")

--------------------------------------------------------------------------------
extraccted_data

--------------------------------------------------------------------------------
## Split the extracted data into Text Chunks

--------------------------------------------------------------------------------
def text_split(extracted_data):
    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500 , chunk_overlap = 20)
    text_chunks=text_splitter.split_documents(extracted_data)
    return text_chunks


--------------------------------------------------------------------------------
text_chunks=text_split(extraccted_data)
print("length of the text_chunk :",len(text_chunks))

--------------------------------------------------------------------------------
## Downloading the Embeddings from Hugging face

--------------------------------------------------------------------------------
def download_hugging_face_embeddings():
    embeddings = HuggingFaceEmbeddings(model_name= "sentence-transformers/all-MiniLM-L6-v2")
    return embeddings

--------------------------------------------------------------------------------
embeddings = download_hugging_face_embeddings()

--------------------------------------------------------------------------------
query_result = embeddings.embed_query("Hello world!")
print("length of the query result :",len(query_result))

--------------------------------------------------------------------------------
# query_result

--------------------------------------------------------------------------------
from dotenv import load_dotenv
load_dotenv()

--------------------------------------------------------------------------------
PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY')
GROQ_API_KEY = os.environ.get('GROQ_API_KEY')

--------------------------------------------------------------------------------
from pinecone import Pinecone, ServerlessSpec

pc = Pinecone(api_key=PINECONE_API_KEY)

--------------------------------------------------------------------------------
index_name = "medicalchatbot"

pc.create_index(
    name=index_name,
    dimension=384, # Replace with your model dimensions
    metric="cosine", # Replace with your model metric
    spec=ServerlessSpec(
        cloud="aws",
        region="us-east-1"
    ) 
)

--------------------------------------------------------------------------------
index_name = "medicalchatbot"

--------------------------------------------------------------------------------
import os
os.environ["PINECONE_API_KEY"]=PINECONE_API_KEY
os.environ["GROQ_API_KEY"]=GROQ_API_KEY


--------------------------------------------------------------------------------
from langchain.vectorstores import Pinecone

docsearch = Pinecone.from_documents(
    documents=text_chunks,
    index_name= index_name,
    embedding=embeddings
)

--------------------------------------------------------------------------------
docsearch

--------------------------------------------------------------------------------
retriver = docsearch.as_retriever(search_type="similarity",search_kwargs={"k":4})

--------------------------------------------------------------------------------
## example of retrival from the pinecone database

--------------------------------------------------------------------------------
retrived_docs = retriver.invoke("what is Malaria?")

--------------------------------------------------------------------------------
retrived_docs

--------------------------------------------------------------------------------
## connecting it  to api

--------------------------------------------------------------------------------
from langchain_groq import ChatGroq
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate

--------------------------------------------------------------------------------
llm = ChatGroq(api_key=GROQ_API_KEY, temperature=0.4, max_tokens=500)

--------------------------------------------------------------------------------
system_prompt = (
    "You are an assistant for question-answering tasks. "
    "Use the following pieces of retrieved context to answer "
    "the question. If you don't know the answer, say that you "
    "don't know. Use three sentences maximum and keep the "
    "answer concise."
    "\n\n"
    "{context}"
)

--------------------------------------------------------------------------------
# Define the prompt template
prompt = ChatPromptTemplate.from_messages(
    [
        ("system", system_prompt),
        ("human", "{input}"),
    ]
)

--------------------------------------------------------------------------------
# Create the question-answering chain
question_answer_chain = create_stuff_documents_chain(llm, prompt)
rag_chain = create_retrieval_chain(retriver,question_answer_chain)

--------------------------------------------------------------------------------
response = rag_chain.invoke({"input":"what is Abscess?"})
print(response["answer"])

--------------------------------------------------------------------------------
response_2 = rag_chain.invoke({"input":"What is Abscess and what are its's Symptoms and prevention ?"})
print(response_2["answer"])

--------------------------------------------------------------------------------


--------------------------------------------------------------------------------
